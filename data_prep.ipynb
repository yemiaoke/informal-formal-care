{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8098699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144ce5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data is from NHATS\n",
    "# read round 1, 2, 5, 6 sp data and sp status data\n",
    "r1_status = pd.read_stata('NHATS_Round_1_Tracker_File.dta')\n",
    "r1_data = pd.read_stata('NHATS_Round_1_SP_File.dta')\n",
    "r1_met = pd.read_stata('NHATS_Round_1_MetNonMet.dta')\n",
    "\n",
    "r2_status = pd.read_stata('NHATS_Round_2_Tracker_File_v2.dta')\n",
    "\n",
    "r5_status = pd.read_stata('NHATS_Round_5_Tracker_File_V3.dta')\n",
    "r5_data = pd.read_stata('NHATS_Round_5_SP_File_V2.dta')\n",
    "r5_met = pd.read_stata('NHATS_Round_5_MetNonMet.dta')\n",
    "\n",
    "r6_status = pd.read_stata('NHATS_Round_6_Tracker_File_V3.dta')\n",
    "\n",
    "# read round 1, 2, 5, 6 cognitive status data\n",
    "r1_cog = pd.read_csv('NHATS_cognition_r1.csv')\n",
    "r2_cog = pd.read_csv('NHATS_cognition_r2.csv')\n",
    "r5_cog = pd.read_csv('NHATS_cognition_r5.csv')\n",
    "r6_cog = pd.read_csv('NHATS_cognition_r6.csv')\n",
    "\n",
    "# read round 1, 2, 5, 6 op data\n",
    "r1_op = pd.read_stata('NHATS_Round_1_OP_File_v2.dta')\n",
    "r5_op = pd.read_stata('NHATS_Round_5_OP_File_V2.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe416506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge round 1 data and round 1 status\n",
    "r1_data = pd.merge(r1_data, r1_status[['spid', 'r1status']], on = ['spid'], how = 'left')\n",
    "\n",
    "# merge round 1 data and round 1 cognitive variables\n",
    "r1_data = pd.merge(r1_data, r1_cog[['spid', 'demclas', 'clock_scorer', 'wordrecall0_20', 'date_prvp']], \n",
    "                   on = ['spid'], how = 'left')\n",
    "\n",
    "# merge round 1 data and round 2 status\n",
    "r1_data = pd.merge(r1_data, r2_status[['spid', 'r2status']], on = ['spid'], how = 'left')\n",
    "\n",
    "# rename round 2 cognitive variables\n",
    "r2_cog.rename(columns={\"demclas\": \"demclas_t1\", \"clock_scorer\": \"clock_scorer_t1\",\n",
    "                       \"wordrecall0_20\": \"wordrecall0_20_t1\", \"date_prvp\": \"date_prvp_t1\"}, inplace=True)\n",
    "\n",
    "# merge round 1 data and round 2 cognitive variables\n",
    "r1_data = pd.merge(r1_data, r2_cog[['spid', 'demclas_t1', 'clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']], \n",
    "                   on = ['spid'], how = 'left')\n",
    "\n",
    "# subsample of persons who did not have dementia in round 1 \n",
    "r1_data = r1_data[r1_data['demclas']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38201981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop persons who had missing value in cognitive tests scores (value < 0)\n",
    "cog_cols = ['clock_scorer', 'wordrecall0_20', 'date_prvp', 'clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']\n",
    "r1_data = r1_data[~(r1_data.loc[:, cog_cols] < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f368985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHATS ognitive tests identified 3 domains of cognitive functioning: memory(wordrecall0_20), orientation(date_prvp),\n",
    "# and executive functioning(clock_scorer)\n",
    "# these scores have different ranges: wordrecall0_20 [0,20], date_prvp [0,8], clock_scorer [0, 5]\n",
    "# standardize the three scores to the same range of [0, 10]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cols_scale = ['clock_scorer', 'wordrecall0_20', 'date_prvp',\n",
    "              'clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']\n",
    "scaled_values = MinMaxScaler().fit_transform(r1_data.loc[:, cols_scale])\n",
    "df_scaled = pd.DataFrame(scaled_values, columns=cols_scale)\n",
    "df_scaled = df_scaled * 10\n",
    "r1_data.loc[:, cols_scale] = df_scaled\n",
    "\n",
    "# create a cognitive score as the sum of the above mentioned 3 scores\n",
    "r1_data['cog_score'] = r1_data[['clock_scorer', 'wordrecall0_20', 'date_prvp']].sum(axis = 1)\n",
    "r1_data['cog_score_t1'] = r1_data[['clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ebde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge round 5 data and round 5 status\n",
    "r5_data = pd.merge(r5_data, r5_status[['spid', 'r5status']], on = ['spid'], how = 'left')\n",
    "\n",
    "# merge round 5 data and round 5 cognitive variables\n",
    "r5_data = pd.merge(r5_data, r5_cog[['spid', 'demclas', 'clock_scorer', 'wordrecall0_20', 'date_prvp']], \n",
    "                   on = ['spid'], how = 'left')\n",
    "\n",
    "# merge round 5 data and round 6 status\n",
    "r5_data = pd.merge(r5_data, r6_status[['spid', 'r6status']], on = ['spid'], how = 'left')\n",
    "\n",
    "# rename round 6 cognitive variables\n",
    "r6_cog.rename(columns={\"demclas\": \"demclas_t1\", \"clock_scorer\": \"clock_scorer_t1\",\n",
    "                       \"wordrecall0_20\": \"wordrecall0_20_t1\", \"date_prvp\": \"date_prvp_t1\"}, inplace=True)\n",
    "\n",
    "# merge round 5 data and round 6 cognitive variables\n",
    "r5_data = pd.merge(r5_data, r6_cog[['spid', 'demclas_t1', 'clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']], \n",
    "                   on = ['spid'], how = 'left')\n",
    "\n",
    "# subsample of persons who did not have dementia in round 5 \n",
    "r5_data = r5_data[r5_data['demclas']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f7ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop persons who had missing value in cognitive tests scores (value < 0)\n",
    "cog_cols = ['clock_scorer', 'wordrecall0_20', 'date_prvp', 'clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']\n",
    "r5_data = r5_data[~(r5_data.loc[:, cog_cols] < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16fd7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHATS ognitive tests identified 3 domains of cognitive functioning: memory(wordrecall0_20), orientation(date_prvp),\n",
    "# and executive functioning(clock_scorer)\n",
    "# these scores have different ranges: wordrecall0_20 [0,20], date_prvp [0,8], clock_scorer [0, 5]\n",
    "# standardize the three scores to the same range of [0, 10]\n",
    "cols_scale = ['clock_scorer', 'wordrecall0_20', 'date_prvp',\n",
    "              'clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']\n",
    "scaled_values = MinMaxScaler().fit_transform(r5_data.loc[:, cols_scale])\n",
    "df_scaled = pd.DataFrame(scaled_values, columns=cols_scale)\n",
    "df_scaled = df_scaled * 10\n",
    "r5_data.loc[:, cols_scale] = df_scaled\n",
    "\n",
    "# create a cognitive score as the sum of the above mentioned 3 scores\n",
    "r5_data['cog_score'] = r5_data[['clock_scorer', 'wordrecall0_20', 'date_prvp']].sum(axis = 1)\n",
    "r5_data['cog_score_t1'] = r5_data[['clock_scorer_t1', 'wordrecall0_20_t1', 'date_prvp_t1']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34c472",
   "metadata": {},
   "source": [
    "# construct a sample of round 1 sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef988a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of relevant variables\n",
    "varlist_sp = ['spid', 'r1dresid', 'is1resptype', 'r1dgender', 'r1d2intvrage', 'cog_score', 'cog_score_t1',\n",
    "              'hc1health', 'hc1disescn3', 'hc1disescn8', 'hc1hosptstay', 'hc1hosovrnht', 'hc1aslep30mn', 'hc1sleepmed',\n",
    "              'ht1retiresen',\n",
    "              'hh1martlstat', 'hh1d2spouage', 'hh1spouseduc', 'hh1spoupchlp', 'hh1livwthspo', 'hh1dlvngarrg', 'hh1dhshldchd',\n",
    "              'hh1dlvngarrg',\n",
    "              'cs1dnumchild', 'cs1dnumdaugh', 'sd1smokedreg', 'sd1smokesnow', \n",
    "              'el1hlthchild', 'el1fingrowup', 'el1higstschl', 'rl1spkothlan', 'ip1nginsnurs',\n",
    "              'hp1ownrentot', 'hp1mrtpadoff', 'ia1totinc', 'ia1toincimf', 'ia1toincim1']\n",
    "varlist_help = ['mo1douthelp', 'mo1dinsdhelp', 'mo1dbedhelp', 'dm1helpmobil', 'ha1moneyhlp', 'sc1eathlp',\n",
    "                'sc1bathhlp', 'sc1toilhlp', 'sc1dreshlp', 'mc1medstrk', 'mc1howpkupm3']\n",
    "varlist_op = ['spid', 'opid', 'op1gender', 'op1relatnshp', 'op1leveledu', 'op1childinhh', 'op1martlstat', 'op1numchldrn',\n",
    "              'op1numchdu18',\n",
    "              'op1ishelper', 'op1helpsched',\n",
    "              'op1numdayswk', 'op1numdaysmn', 'op1numhrsday', 'op1paidhelpr', 'op1dhrsmth',\n",
    "              'op1outhlp', 'op1insdhlp', 'op1bedhlp', 'op1launhlp', 'op1shophlp', 'op1mealhlp', 'op1bankhlp', 'op1moneyhlp',\n",
    "              'op1eathlp', 'op1bathhlp', 'op1toilhlp', 'op1dreshlp', 'op1medshlp', 'op1dochlp', 'op1insurhlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46bcd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_sp = r1_data.loc[:, varlist_sp].copy()\n",
    "r1_op_new = r1_op.loc[:, varlist_op].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3576f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string columns into numeric columns\n",
    "value_map = {'-1 Inapplicable': -1, ' 1 Yes': 1}\n",
    "df = r1_op_new.copy()\n",
    "\n",
    "looplist = ['op1outhlp', 'op1insdhlp', 'op1bedhlp', 'op1launhlp', 'op1shophlp', 'op1mealhlp', 'op1bankhlp', 'op1moneyhlp',\n",
    "            'op1eathlp', 'op1bathhlp', 'op1toilhlp', 'op1dreshlp', 'op1medshlp', 'op1dochlp', 'op1insurhlp', \n",
    "            'op1ishelper']\n",
    "\n",
    "for col in looplist:\n",
    "    df[col] = df[col].map(value_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9ed7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract days and hours information from categorical columns\n",
    "extractlist = ['op1numdayswk', 'op1numdaysmn', 'op1numhrsday', 'op1dhrsmth']\n",
    "for col in extractlist:\n",
    "    # convert category column to string\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].str.extract(r'([+-]?\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9141f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy variable 'got_help' which equals to 1 if sp got helped in any activity or op identified as a helper\n",
    "df['got_help'] = (df[looplist] == 1).any(axis=1).astype(int)\n",
    "\n",
    "# create formal_care dummy which equals to 1 if op is a paid helper\n",
    "df['formal_care'] = np.where(df['op1paidhelpr'] == ' 1 Yes', 1, 0)\n",
    "# create informal_care dummy which equals to 1 if op is not a paid helper\n",
    "helplist = [' 2 No', '-8 DK', '-7 RF']\n",
    "df['informal_care'] = np.where((df['got_help'] == 1) & (df['op1paidhelpr'].isin(helplist)), 1, 0)\n",
    "df['got_help'] = np.where((df['got_help'] < 1) & (df['formal_care'] ==1 ), 1, df['got_help'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97091d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sp may receive care from multiple ops, we consider a \n",
    "# need so sum the hours across different op for each sp\n",
    "# also note that a sp can receive formal and informal care at the same time\n",
    "hours_data = df[['spid', 'got_help', 'formal_care', 'informal_care', 'op1dhrsmth']].copy()\n",
    "hours_data = hours_data.astype(int)\n",
    "\n",
    "formal_data = hours_data[hours_data.formal_care == 1]\n",
    "informal_data = hours_data[hours_data.informal_care == 1]\n",
    "nohelp_data = hours_data[hours_data.got_help == 0]\n",
    "\n",
    "# define functions to apply to columns after groupby\n",
    "max_col = lambda x: x.max()\n",
    "sum_pos_col = lambda x: x[x > 0].sum()\n",
    "\n",
    "formal_hours = formal_data.groupby('spid').agg({'got_help': max_col, 'formal_care': max_col, 'informal_care': max_col,\n",
    "                                                'op1dhrsmth': sum_pos_col}).reset_index()\n",
    "informal_hours = informal_data.groupby('spid').agg({'got_help': max_col, 'formal_care': max_col, 'informal_care': max_col,\n",
    "                                                    'op1dhrsmth': sum_pos_col}).reset_index()\n",
    "nohelp_data = nohelp_data.groupby('spid').agg({'got_help': max_col, 'formal_care': max_col, 'informal_care': max_col,\n",
    "                                               'op1dhrsmth': sum_pos_col}).reset_index()\n",
    "\n",
    "# rename columns for merge\n",
    "formal_hours = formal_hours.rename(columns={'op1dhrsmth': 'formal_hrs'})\n",
    "informal_hours = informal_hours.rename(columns={'op1dhrsmth': 'informal_hrs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a446eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge formal_hours and informal_hours, now we know for each sp, how many hours of each kind of care he/she got.\n",
    "merged = pd.merge(formal_hours, informal_hours, on='spid', how='outer', indicator=True)\n",
    "\n",
    "# recreate got_help, formal_care and informal_care dummies\n",
    "merged['got_help'] = np.nanmax(merged[['got_help_x', 'got_help_y']], axis = 1)\n",
    "merged['formal_care'] = np.nanmax(merged[['formal_care_x', 'formal_care_y']], axis = 1)\n",
    "merged['informal_care'] = np.nanmax(merged[['informal_care_x', 'informal_care_y']], axis = 1)\n",
    "\n",
    "# drop redundant columns\n",
    "merged = merged.drop(['got_help_x', 'got_help_y', 'formal_care_x', 'formal_care_y', 'informal_care_x', 'informal_care_y',\n",
    "                      '_merge'], axis = 1)\n",
    "\n",
    "# rename columns in nohelp_data\n",
    "nohelp_data = nohelp_data.rename(columns={'op1dhrsmth': 'formal_hrs'})\n",
    "nohelp_data['informal_hrs'] = 0\n",
    "# stack nohelp_data and merged\n",
    "sp_hours = pd.concat([merged, nohelp_data], axis=0)\n",
    "sp_hours = sp_hours.sort_values(by = 'spid').reset_index(drop=True)\n",
    "sp_hours.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e88a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if hours information is missing, drop that person from the sample\n",
    "droplist_formal = sp_hours[(sp_hours.formal_hrs==0) & (sp_hours.formal_care==1)].index.to_list()\n",
    "droplist_informal = sp_hours[(sp_hours.informal_hrs==0) & (sp_hours.informal_care==1)].index.to_list()\n",
    "\n",
    "sp_hours = sp_hours.drop(droplist_formal+droplist_informal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "167240dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge care data with sp file\n",
    "r1_sp_merged = pd.merge(r1_sp, sp_hours, on='spid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25bd2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract inforamtion about sp's children\n",
    "children_op = r1_op_new[['spid', 'opid', 'op1relatnshp', 'op1martlstat', 'op1numchldrn', 'op1numchdu18']].copy()\n",
    "children_op = children_op[children_op.op1relatnshp.isin([' 3 DAUGHTER', ' 4 SON'])]\n",
    "\n",
    "# label children who was not married \n",
    "marstat = [' 6 NEVER MARRIED', ' 4 DIVORCED', ' 3 SEPARATED', ' 5 WIDOWED']\n",
    "children_op['not_married_chld'] = np.where(children_op['op1martlstat'].isin(marstat), 1, 0)\n",
    "\n",
    "# label children who did not have their own children\n",
    "children_op['no_child_chld'] = np.where(children_op['op1numchldrn']==0, 1, 0)\n",
    "# label children who did not have children age<18\n",
    "children_op['no_child18_chld'] = np.where(children_op['op1numchdu18']==0, 1, 0)\n",
    "\n",
    "# extract information about whether each sp had a child who was not married, who did not have children\n",
    "# and who did not have children under age 18\n",
    "df = children_op[['spid', 'not_married_chld', 'no_child_chld', 'no_child18_chld']]\n",
    "new_df = df.groupby('spid').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3923b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-23f530c877e7>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  r1_sp_merged.columns = r1_sp_merged.columns.str.replace(pattern, '')\n"
     ]
    }
   ],
   "source": [
    "# merge children data with sp file\n",
    "r1_sp_merged = pd.merge(r1_sp_merged, new_df, on='spid', how='left')\n",
    "\n",
    "# remove the annoying prefixes in column names\n",
    "prefixes = ['^r1', '^is1', '^hc1', '^ht1', '^hh1', '^cs1', '^sd1', '^el1', '^rl1', '^ip1', '^hp1', '^ia1']\n",
    "pattern = '|'.join(prefixes)\n",
    "r1_sp_merged.columns = r1_sp_merged.columns.str.replace(pattern, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "692117d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_sp_merged.to_csv('r1_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56ebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba198cd9",
   "metadata": {},
   "source": [
    "# construct a sample of round 5 sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc49ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of relevant variables\n",
    "varlist_sp = ['spid', 'r5dresid', 'is5resptype', 'r5dgender', 'r5d2intvrage', 'cog_score', 'cog_score_t1',\n",
    "              'hc5health', 'hc5disescn3', 'hc5disescn8', 'hc5hosptstay', 'hc5hosovrnht', 'hc5aslep30mn', 'hc5sleepmed',\n",
    "              'ht5retiresen',\n",
    "              'hh5martlstat', 'hh5dspageall', 'hh5spouseduc', 'hh5spoupchlp', 'hh5livwthspo', 'hh5dlvngarrg', 'hh5dhshldchd',\n",
    "              'hh5dlvngarrg',\n",
    "              'cs5dnumchild', 'cs5dnumdaugh', 'sd5smokedreg', 'sd5smokesnow', \n",
    "              'el5hlthchild', 'el5fingrowup', 'el5higstschl', 'rl5spkothlan', 'ip5nginsnurs',\n",
    "              'hp5ownrentot', 'hp5mrtpadoff', 'ia5totinc', 'ia5toincimf', 'ia5toincim1']\n",
    "varlist_help = ['mo5douthelp', 'mo5dinsdhelp', 'mo5dbedhelp', 'dm5helpmobil', 'ha5moneyhlp', 'sc5eathlp',\n",
    "                'sc5bathhlp', 'sc5toilhlp', 'sc5dreshlp', 'mc5medstrk', 'mc5howpkupm3']\n",
    "varlist_op = ['spid', 'opid', 'op5dgender', 'op5relatnshp', 'op5leveledu', 'op5childinhh', 'op5martlstat', 'op5numchldrn',\n",
    "              'op5numchdu18',\n",
    "              'op5ishelper', 'op5helpsched',\n",
    "              'op5numdayswk', 'op5numdaysmn', 'op5numhrsday', 'op5paidhelpr', 'op5dhrsmth',\n",
    "              'op5outhlp', 'op5insdhlp', 'op5bedhlp', 'op5launhlp', 'op5shophlp', 'op5mealhlp', 'op5bankhlp', 'op5moneyhlp',\n",
    "              'op5eathlp', 'op5bathhlp', 'op5toilhlp', 'op5dreshlp', 'op5medshlp', 'op5dochlp', 'op5insurhlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a33d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r5_sp = r5_data.loc[:, varlist_sp].copy()\n",
    "r5_op_new = r5_op.loc[:, varlist_op].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "932f67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string columns into numeric columns\n",
    "value_map = {'-1 Inapplicable': -1, '1 YES': 1}\n",
    "df = r5_op_new.copy()\n",
    "\n",
    "looplist = ['op5outhlp', 'op5insdhlp', 'op5bedhlp', 'op5launhlp', 'op5shophlp', 'op5mealhlp', 'op5bankhlp', 'op5moneyhlp',\n",
    "            'op5eathlp', 'op5bathhlp', 'op5toilhlp', 'op5dreshlp', 'op5medshlp', 'op5dochlp', 'op5insurhlp', \n",
    "            'op5ishelper']\n",
    "\n",
    "for col in looplist:\n",
    "    df[col] = df[col].map(value_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97e740c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the coding difference between round 1 and round 5\n",
    "df['op5dhrsmth'] = np.where(df['op5dhrsmth'] == '9999 Not codeable, <1 hour/day', 'Not codeable, <1 hour/day', df['op5dhrsmth'])\n",
    "\n",
    "# extract days and hours information from categorical columns\n",
    "extractlist = ['op5numdayswk', 'op5numdaysmn', 'op5numhrsday', 'op5dhrsmth']\n",
    "for col in extractlist:\n",
    "    # convert category column to string\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].str.extract(r'([+-]?\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31250ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy variable 'got_help' which equals to 1 if sp got helped in any activity or op identified as a helper\n",
    "df['got_help'] = (df[looplist] == 1).any(axis=1).astype(float)\n",
    "\n",
    "# create formal_care dummy which equals to 1 if op is a paid helper\n",
    "df['formal_care'] = np.where(df['op5paidhelpr'] == ' 1 Yes', 1, 0)\n",
    "# create informal_care dummy which equals to 1 if op is not a paid helper\n",
    "helplist = [' 2 No', '-8 DK', '-7 RF']\n",
    "df['informal_care'] = np.where((df['got_help'] == 1) & (df['op5paidhelpr'].isin(helplist)), 1, 0)\n",
    "df['got_help'] = np.where((df['got_help'] < 1) & (df['formal_care'] ==1 ), 1, df['got_help'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a36ccf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sp may receive care from multiple ops, we consider a \n",
    "# need so sum the hours across different op for each sp\n",
    "# also note that a sp can receive formal and informal care at the same time\n",
    "hours_data = df[['spid', 'got_help', 'formal_care', 'informal_care', 'op5dhrsmth']].copy()\n",
    "hours_data = hours_data.astype(float)\n",
    "\n",
    "formal_data = hours_data[hours_data.formal_care == 1]\n",
    "informal_data = hours_data[hours_data.informal_care == 1]\n",
    "nohelp_data = hours_data[hours_data.got_help == 0]\n",
    "\n",
    "# define functions to apply to columns after groupby\n",
    "max_col = lambda x: x.max()\n",
    "sum_pos_col = lambda x: x[x > 0].sum()\n",
    "\n",
    "formal_hours = formal_data.groupby('spid').agg({'got_help': max_col, 'formal_care': max_col, 'informal_care': max_col,\n",
    "                                                'op5dhrsmth': sum_pos_col}).reset_index()\n",
    "informal_hours = informal_data.groupby('spid').agg({'got_help': max_col, 'formal_care': max_col, 'informal_care': max_col,\n",
    "                                                    'op5dhrsmth': sum_pos_col}).reset_index()\n",
    "nohelp_data = nohelp_data.groupby('spid').agg({'got_help': max_col, 'formal_care': max_col, 'informal_care': max_col,\n",
    "                                               'op5dhrsmth': sum_pos_col}).reset_index()\n",
    "\n",
    "# rename columns for merge\n",
    "formal_hours = formal_hours.rename(columns={'op5dhrsmth': 'formal_hrs'})\n",
    "informal_hours = informal_hours.rename(columns={'op5dhrsmth': 'informal_hrs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e3ebe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge formal_hours and informal_hours, now we know for each sp, how many hours of each kind of care he/she got.\n",
    "merged = pd.merge(formal_hours, informal_hours, on='spid', how='outer', indicator=True)\n",
    "\n",
    "# recreate got_help, formal_care and informal_care dummies\n",
    "merged['got_help'] = np.nanmax(merged[['got_help_x', 'got_help_y']], axis = 1)\n",
    "merged['formal_care'] = np.nanmax(merged[['formal_care_x', 'formal_care_y']], axis = 1)\n",
    "merged['informal_care'] = np.nanmax(merged[['informal_care_x', 'informal_care_y']], axis = 1)\n",
    "\n",
    "# drop redundant columns\n",
    "merged = merged.drop(['got_help_x', 'got_help_y', 'formal_care_x', 'formal_care_y', 'informal_care_x', 'informal_care_y',\n",
    "                      '_merge'], axis = 1)\n",
    "\n",
    "# rename columns in nohelp_data\n",
    "nohelp_data = nohelp_data.rename(columns={'op5dhrsmth': 'formal_hrs'})\n",
    "nohelp_data['informal_hrs'] = 0\n",
    "# stack nohelp_data and merged\n",
    "sp_hours = pd.concat([merged, nohelp_data], axis=0)\n",
    "sp_hours = sp_hours.sort_values(by = 'spid').reset_index(drop=True)\n",
    "sp_hours.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "576b43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if hours information is missing, drop that person from the sample\n",
    "droplist_formal = sp_hours[(sp_hours.formal_hrs==0) & (sp_hours.formal_care==1)].index.to_list()\n",
    "droplist_informal = sp_hours[(sp_hours.informal_hrs==0) & (sp_hours.informal_care==1)].index.to_list()\n",
    "\n",
    "sp_hours = sp_hours.drop(droplist_formal+droplist_informal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5dc0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge care data with sp file\n",
    "r5_sp_merged = pd.merge(r5_sp, sp_hours, on='spid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a72bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract inforamtion about sp's children\n",
    "children_op = r5_op_new[['spid', 'opid', 'op5relatnshp', 'op5martlstat', 'op5numchldrn', 'op5numchdu18']].copy()\n",
    "children_op = children_op[children_op.op5relatnshp.isin([' 3 DAUGHTER', ' 4 SON'])]\n",
    "\n",
    "# label children who was not married \n",
    "marstat = [' 6 NEVER MARRIED', ' 4 DIVORCED', ' 3 SEPARATED', ' 5 WIDOWED']\n",
    "children_op['not_married_chld'] = np.where(children_op['op5martlstat'].isin(marstat), 1, 0)\n",
    "\n",
    "# label children who did not have their own children\n",
    "children_op['no_child_chld'] = np.where(children_op['op5numchldrn']==0, 1, 0)\n",
    "# label children who did not have children age<18\n",
    "children_op['no_child18_chld'] = np.where(children_op['op5numchdu18']==0, 1, 0)\n",
    "\n",
    "# extract information about whether each sp had a child who was not married, who did not have children\n",
    "# and who did not have children under age 18\n",
    "df = children_op[['spid', 'not_married_chld', 'no_child_chld', 'no_child18_chld']]\n",
    "new_df = df.groupby('spid').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c1fe813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-4e25036f564a>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  r5_sp_merged.columns = r5_sp_merged.columns.str.replace(pattern, '')\n"
     ]
    }
   ],
   "source": [
    "# merge children data with sp file\n",
    "r5_sp_merged = pd.merge(r5_sp_merged, new_df, on='spid', how='left')\n",
    "\n",
    "# remove the annoying prefixes in column names\n",
    "prefixes = ['^r5', '^is5', '^hc5', '^ht5', '^hh5', '^cs5', '^sd5', '^el5', '^rl5', '^ip5', '^hp5', '^ia5']\n",
    "pattern = '|'.join(prefixes)\n",
    "r5_sp_merged.columns = r5_sp_merged.columns.str.replace(pattern, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dc571b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r5_sp_merged.to_csv('r5_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e13b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dc97174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the persons who were just added in round 5\n",
    "r15_merged = pd.merge(r1_sp_merged['spid'], r5_sp_merged, on='spid', how='right', indicator=True)\n",
    "r5_new_sp = r15_merged[r15_merged['_merge'] == 'right_only'].drop(columns=['_merge'])\n",
    "\n",
    "# concatenate round 5 new persons with round 1 persons\n",
    "r5_new_sp = r5_new_sp.rename(columns = {'dspageall': 'd2spouage'}) # variable for spouse's age has different names in r1 and r5\n",
    "r15_concat = pd.concat([r1_sp_merged, r5_new_sp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c215df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r15_concat.to_csv('r15_concat.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a06b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49a96a9",
   "metadata": {},
   "source": [
    "# prepare the sample for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7919cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r15_concat = pd.read_csv('r15_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a3e2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create dummies based on a categorical column\n",
    "def create_dummies(df, col):\n",
    "    counts = df[col].value_counts()\n",
    "    valid_values = counts[counts > 0].index.tolist()\n",
    "    filtered_df = df[df[col].isin(valid_values)]\n",
    "    dummy_cols = pd.get_dummies(filtered_df[col])\n",
    "    df = pd.concat([df, dummy_cols], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5800dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-611f7741a449>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  r15_concat['dresid'] = r15_concat['dresid'].str.replace(r'\\d+\\s', '')\n",
      "<ipython-input-37-611f7741a449>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  r15_concat['dresid'] = r15_concat['dresid'].str.replace(r'^Nursing home.*$', 'Nursing home')\n"
     ]
    }
   ],
   "source": [
    "# residential care\n",
    "# merge 2 (SP interview complete) and 2 (SP interview) into one category also made the strings more concise\n",
    "r15_concat['dresid'] = r15_concat['dresid'].astype('string')\n",
    "r15_concat['dresid'] = r15_concat['dresid'].str.replace(r'\\d+\\s', '')\n",
    "r15_concat['dresid'] = r15_concat['dresid'].str.replace(r'^Residential [Cc]are.*$', 'Residential care', regex = True)\n",
    "r15_concat['dresid'] = r15_concat['dresid'].str.replace(r'^Nursing home.*$', 'Nursing home')\n",
    "r15_concat = create_dummies(r15_concat, 'dresid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e96d02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age category\n",
    "r15_concat['age_cate'] = r15_concat['d2intvrage'].apply(lambda x: int(re.findall(r'^\\d+', x)[0]))\n",
    "\n",
    "# whether the survey was answered by a proxy person\n",
    "r15_concat['proxy'] = np.where(r15_concat['resptype'] == '2 PROXY', 1, 0)\n",
    "\n",
    "# gender\n",
    "r15_concat['male'] = np.where(r15_concat['dgender'] == '1 MALE', 1, 0)\n",
    "\n",
    "# spouse age\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat = r15_concat[~r15_concat['d2spouage'].isin(['-8 DK', '-8 - DK', '-7 - RF', '-7 RF'])]\n",
    "r15_concat['d2spouage'] = r15_concat['d2spouage'].str.strip()\n",
    "r15_concat['spouse_age'] = r15_concat['d2spouage'].apply(lambda x: int(re.findall(r'^-?\\d+', x)[0]))\n",
    "\n",
    "# spouse need help\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat = r15_concat[~r15_concat['spoupchlp'].isin(['-8 DK', '-7 RF'])]\n",
    "r15_concat['spoupchlp'] = r15_concat['spoupchlp'].str.strip()\n",
    "r15_concat['spou_need_help'] = r15_concat['spoupchlp'].replace({'2 NO': 0, '-1 Inapplicable': -1, '1 YES': 1})\n",
    "\n",
    "# live with spouse\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat['livwthspo'] = r15_concat['livwthspo'].str.strip()\n",
    "r15_concat['livewth_spou'] = r15_concat['livwthspo'].replace({'2 NO': 0, '-1 Inapplicable': 0, '1 YES': 1})\n",
    "\n",
    "# live alone\n",
    "r15_concat['live_alone'] = np.where(r15_concat['dlvngarrg'].isin(['1 Alone ', '1 Alone']), 1, 0)\n",
    "\n",
    "# finacial condition when growing up\n",
    "r15_concat = r15_concat[~r15_concat['fingrowup'].isin(['-8 DK', '-7 RF', '-1 Inapplicable'])]\n",
    "r15_concat['fingrowup'] = r15_concat['fingrowup'].str.strip()\n",
    "r15_concat['rich_chld'] = r15_concat['fingrowup'].apply(lambda x: 6-int(re.findall(r'^\\d+', x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef8af6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general health condition\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat = r15_concat[r15_concat['health'] != '-8 DK']\n",
    "r15_concat['health'] = r15_concat['health'].str.strip()\n",
    "r15_concat['health'] = r15_concat['health'].apply(lambda x: 6-int(re.findall(r'^\\d+', x)[0]))\n",
    "\n",
    "# high blood pressure\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat = r15_concat[r15_concat['disescn3'] != '-8 DK']\n",
    "r15_concat['disescn3'] = np.where(r15_concat['disescn3'] == '7 PREVIOUSLY REPORTED', '1 YES', r15_concat['disescn3'])\n",
    "r15_concat['disescn3'] = r15_concat['disescn3'].str.strip()\n",
    "r15_concat['high_blood'] = np.where(r15_concat['disescn3'] == '1 YES', 1, 0)\n",
    "\n",
    "# stroke\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat = r15_concat[r15_concat['disescn8'] != '-8 DK']\n",
    "r15_concat['disescn8'] = r15_concat['disescn8'].str.strip()\n",
    "r15_concat['stroke'] = np.where(r15_concat['disescn8'] == '1 YES', 1, 0)\n",
    "\n",
    "# sleep quality\n",
    "# remove missings and convert strings to integer\n",
    "r15_concat = r15_concat[r15_concat['aslep30mn'] != '-8 DK']\n",
    "r15_concat['aslep30mn'] = r15_concat['aslep30mn'].str.strip()\n",
    "r15_concat['sleep'] = r15_concat['aslep30mn'].apply(lambda x: int(re.findall(r'^\\d+', x)[0]))\n",
    "\n",
    "# smoked regularly\n",
    "r15_concat = r15_concat[~r15_concat['smokedreg'].isin(['-8 DK', '-7 RF', '-1 Inapplicable'])]\n",
    "r15_concat['smokedreg'] = r15_concat['smokedreg'].str.strip()\n",
    "r15_concat['smoke_reg'] = r15_concat['smokedreg'].apply(lambda x: 2-int(re.findall(r'^\\d+', x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af3e4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education\n",
    "r15_concat = r15_concat[~r15_concat['higstschl'].isin(['-8 DK', '-7 RF'])]\n",
    "r15_concat['higstschl'] = r15_concat['higstschl'].str.strip()\n",
    "# create 4 dummies, baseline is high school drop-out, then high school graduate, \n",
    "# then some college (include vocational school ect), then college graduate, then above college.\n",
    "r15_concat['higschgra'] = np.where(r15_concat['higstschl'] == '4 HIGH SCHOOL GRADUATE (HIGH SCHOOL DIPLOMA OR EQUIVALENT)',\n",
    "                                   1, 0)\n",
    "r15_concat['somcol'] = np.where(r15_concat['higstschl'].\\\n",
    "                                isin(['5 VOCATIONAL, TECHNICAL, BUSINESS, OR TRADE SCHOOL CERTIFICATE OR DIPLOMA (BEYOND HIGH SCHOOL LEVEL)',\\\n",
    "                                      '6 SOME COLLEGE BUT NO DEGREE',\\\n",
    "                                      \"7 ASSOCIATE'S DEGREE\"]), 1, 0)\n",
    "r15_concat['colgra'] = np.where(r15_concat['higstschl'] == \"8 BACHELOR'S DEGREE\", 1, 0)\n",
    "r15_concat['colabo'] = np.where(r15_concat['higstschl'] == \"9 MASTER'S, PROFESSIONAL, OR DOCTORAL DEGREE\", 1, 0)\n",
    "\n",
    "# bilingual\n",
    "r15_concat = r15_concat[~r15_concat['spkothlan'].isin(['-8 DK', '-1 Inapplicable'])]\n",
    "r15_concat['spkothlan'] = r15_concat['spkothlan'].str.strip()\n",
    "r15_concat['bilingual'] = r15_concat['spkothlan'].apply(lambda x: 2-int(re.findall(r'^\\d+', x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96ef19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income\n",
    "r15_concat = r15_concat[~r15_concat['toincim1'].isin(['-1 Inapplicable'])]\n",
    "r15_concat['income'] = pd.to_numeric(r15_concat['toincim1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2cd6fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spid', 'dresid', 'resptype', 'dgender', 'd2intvrage', 'cog_score', 'cog_score_t1', 'health', 'disescn3', 'disescn8', 'hosptstay', 'hosovrnht', 'aslep30mn', 'sleepmed', 'retiresen', 'martlstat', 'd2spouage', 'spouseduc', 'spoupchlp', 'livwthspo', 'dlvngarrg', 'dhshldchd', 'dlvngarrg.1', 'dnumchild', 'dnumdaugh', 'smokedreg', 'smokesnow', 'hlthchild', 'fingrowup', 'higstschl', 'spkothlan', 'nginsnurs', 'ownrentot', 'mrtpadoff', 'totinc', 'toincimf', 'toincim1', 'formal_hrs', 'informal_hrs', 'got_help', 'formal_care', 'informal_care', 'not_married_chld', 'no_child_chld', 'no_child18_chld', 'Community ', 'Nursing home', 'Residential care', 'age_cate', 'proxy', 'male', 'spouse_age', 'spou_need_help', 'livewth_spou', 'live_alone', 'rich_chld', 'high_blood', 'stroke', 'sleep', 'smoke_reg', 'higschgra', 'somcol', 'colgra', 'colabo', 'bilingual', 'income'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r15_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64cedebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant variable list\n",
    "var4reg = ['spid', 'cog_score', 'cog_score_t1', 'health', 'dnumchild', 'dnumdaugh', 'formal_hrs', 'informal_hrs', \n",
    "           'got_help', 'formal_care', 'informal_care', 'not_married_chld', 'no_child_chld', 'no_child18_chld', \n",
    "           'Community ', 'Nursing home', 'age_cate', 'proxy', 'male', 'spouse_age', 'spou_need_help', 'livewth_spou',\n",
    "           'live_alone', 'rich_chld', 'high_blood', 'stroke', 'sleep', 'smoke_reg', 'higschgra', 'somcol', 'colgra',\n",
    "           'colabo', 'bilingual', 'income'\n",
    "           ]\n",
    "\n",
    "final_sample = r15_concat.loc[:, var4reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b3fe942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitler out persons whose initial cognitive test scores are 0\n",
    "final_sample = final_sample[final_sample['cog_score'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b0e900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the change in cognitive test score\n",
    "final_sample['cog_diff'] = final_sample['cog_score_t1'] - final_sample['cog_score']\n",
    "final_sample['cog_diff_perc'] = final_sample['cog_diff'] / final_sample['cog_score'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18640498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spid</th>\n",
       "      <th>cog_score</th>\n",
       "      <th>cog_score_t1</th>\n",
       "      <th>health</th>\n",
       "      <th>dnumchild</th>\n",
       "      <th>dnumdaugh</th>\n",
       "      <th>formal_hrs</th>\n",
       "      <th>informal_hrs</th>\n",
       "      <th>got_help</th>\n",
       "      <th>formal_care</th>\n",
       "      <th>informal_care</th>\n",
       "      <th>not_married_chld</th>\n",
       "      <th>no_child_chld</th>\n",
       "      <th>no_child18_chld</th>\n",
       "      <th>Community</th>\n",
       "      <th>Nursing home</th>\n",
       "      <th>age_cate</th>\n",
       "      <th>proxy</th>\n",
       "      <th>male</th>\n",
       "      <th>spouse_age</th>\n",
       "      <th>spou_need_help</th>\n",
       "      <th>livewth_spou</th>\n",
       "      <th>live_alone</th>\n",
       "      <th>rich_chld</th>\n",
       "      <th>high_blood</th>\n",
       "      <th>stroke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>smoke_reg</th>\n",
       "      <th>higschgra</th>\n",
       "      <th>somcol</th>\n",
       "      <th>colgra</th>\n",
       "      <th>colabo</th>\n",
       "      <th>bilingual</th>\n",
       "      <th>income</th>\n",
       "      <th>cog_diff</th>\n",
       "      <th>cog_diff_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.360000e+03</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5305.000000</td>\n",
       "      <td>5305.000000</td>\n",
       "      <td>5305.000000</td>\n",
       "      <td>5305.000000</td>\n",
       "      <td>5305.000000</td>\n",
       "      <td>4295.000000</td>\n",
       "      <td>4295.000000</td>\n",
       "      <td>4295.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.0</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.00000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5.360000e+03</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.108402e+07</td>\n",
       "      <td>14.796331</td>\n",
       "      <td>16.709188</td>\n",
       "      <td>3.263806</td>\n",
       "      <td>2.916418</td>\n",
       "      <td>1.467724</td>\n",
       "      <td>3.290858</td>\n",
       "      <td>13.339303</td>\n",
       "      <td>0.329123</td>\n",
       "      <td>0.057304</td>\n",
       "      <td>0.308577</td>\n",
       "      <td>0.622119</td>\n",
       "      <td>0.450058</td>\n",
       "      <td>0.642375</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.855037</td>\n",
       "      <td>0.017537</td>\n",
       "      <td>0.374254</td>\n",
       "      <td>2.574254</td>\n",
       "      <td>-0.455784</td>\n",
       "      <td>0.489179</td>\n",
       "      <td>0.335075</td>\n",
       "      <td>2.590672</td>\n",
       "      <td>0.686194</td>\n",
       "      <td>0.102612</td>\n",
       "      <td>3.469403</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>0.299627</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>0.123134</td>\n",
       "      <td>0.105597</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>5.426765e+04</td>\n",
       "      <td>1.912858</td>\n",
       "      <td>34.364501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.103489e+06</td>\n",
       "      <td>5.674641</td>\n",
       "      <td>8.173339</td>\n",
       "      <td>1.076733</td>\n",
       "      <td>1.927427</td>\n",
       "      <td>1.298112</td>\n",
       "      <td>33.696846</td>\n",
       "      <td>62.875561</td>\n",
       "      <td>0.469939</td>\n",
       "      <td>0.232445</td>\n",
       "      <td>0.461950</td>\n",
       "      <td>0.484914</td>\n",
       "      <td>0.497557</td>\n",
       "      <td>0.479357</td>\n",
       "      <td>0.189546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.474189</td>\n",
       "      <td>0.131274</td>\n",
       "      <td>0.483975</td>\n",
       "      <td>3.786188</td>\n",
       "      <td>0.583649</td>\n",
       "      <td>0.499930</td>\n",
       "      <td>0.472061</td>\n",
       "      <td>1.021319</td>\n",
       "      <td>0.464082</td>\n",
       "      <td>0.303480</td>\n",
       "      <td>1.283116</td>\n",
       "      <td>0.49989</td>\n",
       "      <td>0.458137</td>\n",
       "      <td>0.444848</td>\n",
       "      <td>0.328622</td>\n",
       "      <td>0.307350</td>\n",
       "      <td>0.349633</td>\n",
       "      <td>1.907195e+05</td>\n",
       "      <td>8.439319</td>\n",
       "      <td>132.612523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-26.666667</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000227e+07</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-2.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000468e+07</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.900000e+04</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>24.337979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000683e+07</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000e+04</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>61.797753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000251e+07</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>974.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.700000e+06</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>2825.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               spid    cog_score  cog_score_t1       health    dnumchild    dnumdaugh   formal_hrs  informal_hrs     got_help  formal_care  informal_care  not_married_chld  no_child_chld  no_child18_chld   Community   Nursing home     age_cate        proxy         male   spouse_age  spou_need_help  livewth_spou   live_alone    rich_chld   high_blood       stroke        sleep   smoke_reg    higschgra       somcol       colgra       colabo    bilingual        income     cog_diff  cog_diff_perc\n",
       "count  5.360000e+03  5360.000000   5360.000000  5360.000000  5360.000000  5360.000000  5305.000000   5305.000000  5305.000000  5305.000000    5305.000000       4295.000000    4295.000000      4295.000000  5360.000000        5360.0  5360.000000  5360.000000  5360.000000  5360.000000     5360.000000   5360.000000  5360.000000  5360.000000  5360.000000  5360.000000  5360.000000  5360.00000  5360.000000  5360.000000  5360.000000  5360.000000  5360.000000  5.360000e+03  5360.000000    5360.000000\n",
       "mean   1.108402e+07    14.796331     16.709188     3.263806     2.916418     1.467724     3.290858     13.339303     0.329123     0.057304       0.308577          0.622119       0.450058         0.642375     0.962687           0.0     2.855037     0.017537     0.374254     2.574254       -0.455784      0.489179     0.335075     2.590672     0.686194     0.102612     3.469403     0.51250     0.299627     0.271642     0.123134     0.105597     0.142537  5.426765e+04     1.912858      34.364501\n",
       "std    3.103489e+06     5.674641      8.173339     1.076733     1.927427     1.298112    33.696846     62.875561     0.469939     0.232445       0.461950          0.484914       0.497557         0.479357     0.189546           0.0     1.474189     0.131274     0.483975     3.786188        0.583649      0.499930     0.472061     1.021319     0.464082     0.303480     1.283116     0.49989     0.458137     0.444848     0.328622     0.307350     0.349633  1.907195e+05     8.439319     132.612523\n",
       "min    1.000000e+07     0.666667      0.000000     1.000000     0.000000     0.000000     0.000000      0.000000     0.000000     0.000000       0.000000          0.000000       0.000000         0.000000     0.000000           0.0     1.000000     0.000000     0.000000    -1.000000       -1.000000      0.000000     0.000000     1.000000     0.000000     0.000000     1.000000     0.00000     0.000000     0.000000     0.000000     0.000000     0.000000  0.000000e+00   -26.666667    -100.000000\n",
       "25%    1.000227e+07    10.666667     14.500000     3.000000     2.000000     1.000000     0.000000      0.000000     0.000000     0.000000       0.000000          0.000000       0.000000         0.000000     1.000000           0.0     2.000000     0.000000     0.000000    -1.000000       -1.000000      0.000000     0.000000     2.000000     0.000000     0.000000     3.000000     0.00000     0.000000     0.000000     0.000000     0.000000     0.000000  1.500000e+04    -0.500000      -2.702703\n",
       "50%    1.000468e+07    14.833333     19.250000     3.000000     3.000000     1.000000     0.000000      0.000000     0.000000     0.000000       0.000000          1.000000       0.000000         1.000000     1.000000           0.0     3.000000     0.000000     0.000000    -1.000000       -1.000000      0.000000     0.000000     3.000000     1.000000     0.000000     4.000000     1.00000     0.000000     0.000000     0.000000     0.000000     0.000000  2.900000e+04     3.833333      24.337979\n",
       "75%    1.000683e+07    19.000000     22.500000     4.000000     4.000000     2.000000     0.000000      2.000000     1.000000     0.000000       1.000000          1.000000       1.000000         1.000000     1.000000           0.0     4.000000     0.000000     1.000000     6.000000        0.000000      1.000000     1.000000     3.000000     1.000000     0.000000     5.000000     1.00000     1.000000     1.000000     0.000000     0.000000     0.000000  5.500000e+04     7.333333      61.797753\n",
       "max    2.000251e+07    29.333333     29.000000     5.000000    14.000000    10.000000   974.000000   1072.000000     1.000000     1.000000       1.000000          1.000000       1.000000         1.000000     1.000000           0.0     6.000000     1.000000     1.000000    10.000000        1.000000      1.000000     1.000000     5.000000     1.000000     1.000000     5.000000     1.00000     1.000000     1.000000     1.000000     1.000000     1.000000  5.700000e+06    20.500000    2825.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7bb2edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sample.to_csv('final_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba464fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
